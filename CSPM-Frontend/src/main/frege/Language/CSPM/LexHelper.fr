module Language.CSPM.LexHelper inline (eitherT, hoistEither)

where

import Language.CSPM.Lexer as Lexer (scanner)
import Language.CSPM.Token (Token, LexError)
import Language.CSPM.TokenClasses (PrimToken)
import Language.CSPM.UnicodeSymbols (lookupDefaultSymbol)

import Data.DList(DList)
import Data.DList as DList()
import frege.control.monad.trans.MonadIO 
import frege.data.Set (Set)

import System.FilePath(FilePath,isAbsolute,splitDirectories,normalise,joinPath)
import frege.control.monad.trans.EitherT

--- Given a pair of actions, one to perform in case of failure, and one to perform
--- in case of success, run an 'EitherT' and get back a monadic result.
--- copied from https://hackage.haskell.org/package/either-4.4.1/docs/src/Control-Monad-Trans-Either.html
eitherT :: Monad m => (a -> m c) -> (b -> m c) -> EitherT a m b -> m c
eitherT f g (EitherT m) = m >>= \z -> case z of
    Left a -> f a
    Right b -> g b

--- Lift an 'Either' into an 'EitherT'
hoistEither :: Monad m => Either e a -> EitherT e m a
hoistEither = EitherT . return
{-# INLINE hoistEither #-}


--- Lex a String.
lexPlain :: String -> Either LexError [Token]
lexPlain src = fmap reverse $ Lexer.scanner src

--- Convert a token to a String.
--- If the tokenClasss has a Unicode symbol return the default Unicode string.
unicodeTokenString :: Token -> String
unicodeTokenString token
  = case lookupDefaultSymbol $ token.tokenClass of
      Just (unicodeSymbol, _) -> packed [unicodeSymbol]
      Nothing -> token.tokenString

--- Convert a token to a String.
--- If the tokenClasss has a Unicode symbol return the default ASCII string.
asciiTokenString :: Token -> String
asciiTokenString token
  = case lookupDefaultSymbol $ token.tokenClass of
      Just (_, symbol) -> symbol
      Nothing -> token.tokenString

type Chunk = [Token]
type Chunks = DList Chunk
data FilePart
    = Toks    Chunk
    | Include FilePath
derive Show FilePart

--- lex input-string and import all includes files
lexInclude :: FilePath -> String -> IO (Either LexError [Token])
lexInclude srcName input
   = eitherT (return . Left) (return . Right . concat . DList.toList) $ lexInclude2 srcName input

private lexInclude2 :: FilePath -> String -> EitherT LexError IO Chunks
private lexInclude2 srcName input = do
        hoistEither $ lexPlain input
    >>= hoistEither . splitIncludes []
    >>= mapM (processPart srcName)
    >>= return . DList.concat

private processPart :: FilePath -> FilePart -> EitherT LexError IO Chunks
private processPart srcName part = case part of
    Toks ch -> return $ DList.singleton ch
    Include fname -> (MonadIO.liftIO $ readFile absolutePath) >>= lexInclude2 absolutePath
     where
       absolutePath = getAbsoluteIncludeFileName srcName fname 

--- micro-parser for include-statements
private splitIncludes :: [Token] -> [Token] -> Either LexError [FilePart]
private splitIncludes acc  []  = return [Toks $ reverse acc]
private splitIncludes acc (h:rest) = case h of
    tok@(Token _ _ _ L_Include _) -> do
        r <- scanInclude tok rest
        return $ (Toks $ reverse acc) : r
    _ -> splitIncludes (h:acc) rest

private scanInclude :: Token -> [Token] -> Either LexError [FilePart]
private scanInclude incl (h:rest) = case h of
    Token _ _ _ T_WhiteSpace _ -> scanInclude incl rest
    Token _ _ _ L_String fname -> do
       r <- splitIncludes [] rest
       let fileName = packed $ reverse $ tail $ reverse $ tail $ unpacked fname -- remove quotes
       return $ (Include fileName) : r
    _ -> Left $ LexError {
       lexEPos = incl.tokenStart
      ,lexEMsg = "Include without filename"
      }


private scanInclude incl _ = Left $ LexError {
       lexEPos = incl.tokenStart
      ,lexEMsg = "Include without filename at end of file"
      }


--- Remove comments, whitespaces and unneeded newlines.
removeIgnoredToken :: [Token] -> [Token]
removeIgnoredToken = soakNewlines . removeComments
  where
    -- | Remove comments from the token stream.
    removeComments :: [Token] -> [Token]
    removeComments = filter (\t -> not (tokenIsComment t || isWhiteSpace t))
    isWhiteSpace = (==) T_WhiteSpace . Token.tokenClass

--- Is the token a line-comment, block-comment or a Pragma?
tokenIsComment :: Token -> Bool
tokenIsComment t = tc == L_LComment || tc == L_BComment || tc == L_Pragma
  where tc = t.tokenClass


--- remove newlines, that do not end a declaration from the token stream.
--- For example newlines next to binary operators.
--- Remove all trailing newlines.
soakNewlines :: [Token] -> [Token]
soakNewlines = worker
  where
    worker [] = []
    worker [x] | x.tokenClass == L_Newline = []
    worker [x] = [x]
    worker (h1:h2:t) = case (h1.tokenClass, h2.tokenClass) of
       (L_Newline, L_Newline) -> worker (h1:t)
       (L_Newline, _) | isH2NewLineConsumer -> worker $ h2:t
       (L_Newline, _) -> h1 : (worker $ h2:t)
       (_, L_Newline) | isH1NewLineConsumer -> worker $ h1:t
       (_, L_Newline) -> h1: (worker $ h2:t)
       _   -> h1: (worker $ h2:t)
      where
        isH2NewLineConsumer = Set.member h2.tokenClass consumeNLBeforeToken
        isH1NewLineConsumer = Set.member h1.tokenClass consumeNLAfterToken

    binaryOperators =
     [T_is, T_hat, T_hash, T_times, T_slash,
      T_percent, T_plus, T_minus, T_eq, T_neq,
      T_ge, T_le, T_not, T_amp, T_semicolon,
      T_comma, T_triangle, T_box, T_rhd, T_exp,
      T_sqcap, T_interleave, T_backslash, T_parallel,
      T_mid, T_at, T_atat, T_rightarrow, T_leftarrow,
      T_leftrightarrow, T_dot, T_dotdot, T_exclamation,
      T_questionmark, T_colon, T_openBrack, T_closeBrack,
      T_openOxBrack, T_closeOxBrack,T_openPBrace,
      T_openBrackBrack, T_if, T_then,T_else, T_let, T_and,
      T_or, T_Refine, T_trace,T_failure, T_failureDivergence,
      T_refusalTesting, T_refusalTestingDiv, T_revivalTesting,
      T_revivalTestingDiv,T_tauPriorityOp, T_model_check, T_within,
      T_LTL, T_CTL]
    consumeNLBeforeToken
      = Set.fromList (
            [T_closeParen, T_gt, T_closeBrace, T_closeBrackBrack, T_closeSpecialBrack, T_closePBrace]
         ++ binaryOperators)
    consumeNLAfterToken
      = Set.fromList ( [T_openParen, T_openBrace, T_lt] ++ binaryOperators)

--- 'getAbsoluteIncludeFileName' determines the absolute path of an include file name.
--- 'getAbsoluteIncludeFileName' makes it possible to include other CSP modules by 
--- giving the file path locally w.r.t. the current file path of the CSP module 
--- which includes the particular CSP modules.
private getAbsoluteIncludeFileName :: FilePath -> FilePath -> FilePath
private getAbsoluteIncludeFileName srcFileName inclFileName
   = case isAbsolute inclFileName of 
  True  -> inclFileName 
  False -> joinPath $ (
    take ((length srcDirSequence)-(countBackDirs fileDirSequence)) srcDirSequence 
      ++ (removeBackDirs fileDirSequence))
 where
    fileDirSequence = splitDirectories $ normalise inclFileName
    srcDirSequence  = init $ splitDirectories $ normalise srcFileName
    countBackDirs   = length . filter (".." ==) 
    removeBackDirs  = dropWhile (".." == )
